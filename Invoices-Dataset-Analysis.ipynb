{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "78cb3d7c",
   "metadata": {},
   "source": [
    "# Programming in Data Science - Final Project\n",
    "## Invoices Dataset Analysis\n",
    "**Team Members: Leo WINTER, Yoann SUBLET, Kellian VERVAELE KLEIN, Alvaro SERERO**\n",
    "\n",
    "Dataset: Invoices (Kaggle)\n",
    "\n",
    "Source: https://www.kaggle.com/datasets/cankatsrc/invoices/data\n",
    "\n",
    "This dataset includes multiple fields such as customer details (first name, last name, email), transaction information (product ID, quantity, amount, invoice date), and additional attributes like address, city, and stock code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9cb51c4",
   "metadata": {},
   "source": [
    "### Import all needed libraries for the project:\n",
    "- Pandas for data manipulation\n",
    "- Plotly express for visualizations\n",
    "- Dash for creating a visual and interactive dashboard interface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "fcdd6c16",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\leoma\\Documents\\anaconda3\\envs\\prophet_env\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import plotly.express as px\n",
    "import plotly.graph_objects as go\n",
    "from dash import Dash, dcc, html,Input, Output\n",
    "from dash import callback\n",
    "from prophet import Prophet\n",
    "from prophet.plot import plot_plotly\n",
    "import logging\n",
    "\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "324203ca",
   "metadata": {},
   "source": [
    "## 1) Data collection and exploration"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a26496a",
   "metadata": {},
   "source": [
    "### Function to safely load CSV data from a file path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3179ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(file_path: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to load CSV data from a given file path safely.\n",
    "\n",
    "    Input: \n",
    "    ------\n",
    "    file_path => String, path to the CSV file\n",
    "\n",
    "    Output: \n",
    "    ------\n",
    "    dataset => pd.DataFrame containing the loaded data\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(file_path)\n",
    "        print(\"Data loaded successfully.\")\n",
    "        return df\n",
    "    \n",
    "    # in case an error is generated when we try to read the file\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading data: {e}\")\n",
    "        return pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d423915",
   "metadata": {},
   "source": [
    "### Function to process invalid first_name and last_name columns.\n",
    "- In the initial dataset there are \"last_name\" and \"first_name\" columns but each one contains a combination of a first name and last name which does not make sense since a trasaction is only made by one individual person and columns should contain exactly what is described by their name.\n",
    "- For example, the first line is structured as follows, which is a mistake and need to be corrected.\n",
    "\n",
    "first_name | last_name  \n",
    "Carmen Nixon | Todd Anderson"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d601f854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_treatment(dataset: pd.DataFrame, options: str = \"first\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to treat first_name and last_name columns in a dataset.\n",
    "\n",
    "    Only use this function if both first_name and last_name columns have already\n",
    "    the full name (first + last name)!!!\n",
    "    This function does not fuse firts_name and last_name column in a column name\n",
    "\n",
    "    \n",
    "    Input:\n",
    "    ---------\n",
    "    - dataset => Pandas DataFrame, dataset must have first_name and last_name columns\n",
    "    - options => String, options for treatment between \"separate\", \"first\" and \"last\"\n",
    "        - \"separate\": create two new line for each name, \n",
    "        - \"first\" (default): keep only the first_name renamed as name, \n",
    "        - \"last\" : keep only the last_name renamed as name\n",
    "    \n",
    "    Output:\n",
    "    ---------\n",
    "    - dataset => Pandas DataFrame after treating first_name and last_name columns\n",
    "    \"\"\"\n",
    "    # We first check that both columns 'first_name' and 'lst_name' are present in the dataset\n",
    "    if \"first_name\" in dataset and \"last_name\" in dataset:\n",
    "        if options == \"separate\":\n",
    "            value = dataset.columns.difference(['first_name','last_name']).tolist()\n",
    "            # Create a new dataset that duplicate every line in dataset, and create one line with\n",
    "            # a column named 'name' with the value  of 'first_name' and the second line with\n",
    "            # a column named 'name' with the value  of 'last_name'\n",
    "            new_dataset = pd.melt(dataset, id_vars=value,              \n",
    "                              value_vars=['first_name', 'last_name'],\n",
    "                              value_name='name')\n",
    "            \n",
    "            # Delete variable column and put the newly created 'name' column as the first column of the dataset\n",
    "            column_to_keep = [col for col in new_dataset.columns if col not in [\"name\", \"variable\"]]\n",
    "            new_order = [\"name\"] + column_to_keep\n",
    "            new_dataset = new_dataset[new_order]\n",
    "\n",
    "        elif options == \"first\":\n",
    "            # Delete the 'last_name' column\n",
    "            new_dataset = dataset.drop(columns=['last_name'])\n",
    "            # Rename 'first_name' column into 'name'\n",
    "            new_dataset.rename(columns={'first_name': 'name'}, inplace=True)\n",
    "\n",
    "        elif options == \"last\":\n",
    "            # Delete the 'first_name' column\n",
    "            new_dataset = dataset.drop(columns=['first_name'])\n",
    "            # Rename 'last_name' column into 'name'\n",
    "            new_dataset.rename(columns={'last_name': 'name'}, inplace=True)\n",
    "        else:\n",
    "            # If the parameter is not a correct options \n",
    "            print(f\"{options} is not a correct parameters of options, please write 'separate' or 'first' or 'last\")\n",
    "            return dataset\n",
    "        return new_dataset\n",
    "    else:\n",
    "        return dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26aeba0c",
   "metadata": {},
   "source": [
    "### Function to parse invoice dates:\n",
    "- Convert \"invoice_date\" column to datetime for futural temporal manipulations.\n",
    "- Extracts year, month, day, and day of week features."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bdbddd07",
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_dates(df: pd.DataFrame,date_column: str, date_format: str=\"%d/%m/%Y\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Converts \"invoice_date\" column from string to datetime.\n",
    "    Extracts year, month, day, and day of week features.\n",
    "\n",
    "    Input:\n",
    "    ------\n",
    "    - df (DataFrame) - dataset with invoice_date column\n",
    "\n",
    "    Output:\n",
    "    ------\n",
    "    - df (DataFrame) - dataset with parsed datetime features\n",
    "    \"\"\"\n",
    "    # We first check that the name of the column in the variable <date_column> is in the dataset\n",
    "    if date_column not in df.columns:\n",
    "        print(f\"Column '{date_column}' not found in DataFrame.\")\n",
    "        return df\n",
    "    \n",
    "    format_date = ['%Y-%m-%d','%d-%m-%Y','%Y/%m/%d','%d/%m/%Y']\n",
    "    # Check if the format of the time column given is a format that work with the function pd.to_datetime\n",
    "    # The correct format allowed are put in the format_date list \n",
    "    if date_format in format_date:\n",
    "        df = df.copy()\n",
    "        # Put the time column into a DatetimeFormat\n",
    "        df[date_column] = pd.to_datetime(df[date_column], format=date_format, errors='coerce')\n",
    "        # In case the datetime format is not '%d/%m/%Y', transform into it into '%d/%m/%Y' format\n",
    "        if (date_format != \"%d/%m/%Y\"):\n",
    "            df[date_column] = df[date_column].dt.strftime('%d/%m/%Y')\n",
    "            df[date_column] = pd.to_datetime(df[date_column], format='%d/%m/%Y', errors='coerce')\n",
    "        # Create int column with year, month, day, dayofweek from the real date in column date_column\n",
    "        df['year'] = df[date_column].dt.year\n",
    "        df['month'] = df[date_column].dt.month\n",
    "        df['day'] = df[date_column].dt.day\n",
    "        df['dayofweek'] = df[date_column].dt.dayofweek\n",
    "    else:\n",
    "        print(\"Wrong date format type\")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b195a4b0",
   "metadata": {},
   "source": [
    "### Covert all string columns of the dataset to strip whitespaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d31a7949",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_string_columns(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    String manipulation: Strip whitespace from object columns\n",
    "\n",
    "    Input:\n",
    "    -------\n",
    "    - df => Pandas DataFrame to be processed\n",
    "    Output:\n",
    "    ------- \n",
    "    None (the function modifies the DataFrame in place)\n",
    "    \"\"\"\n",
    "    # Put every 'object' column in string_cols variable\n",
    "    string_cols = df.select_dtypes(include=['object']).columns\n",
    "    # Strip whitespace in every column in string_col\n",
    "    for col in string_cols:\n",
    "        df[col] = df[col].str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd25a8dc",
   "metadata": {},
   "source": [
    "### Function to preprocess the initial loaded dataset: combines all the previous functions and returns a clean dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "adfd629e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_data(df: pd.DataFrame,date_column: str,date_format: str=\"%d/%m/%Y\", name_options: str = \"first\") -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Function to preprocess the initial loaded dataset:\n",
    "    - Strips whitespaces from strings using the convert_string_columns function. \n",
    "    - Converts \"invoice_date\" column to datetime for futural temporal manipulations.\n",
    "    - Adds \"revenue\" column derived from \"qty\" and \"amount\" columns.\n",
    "    - Create a column name using the name_treatment function correcting the first_name and last_name column\n",
    "\n",
    "    Input:\n",
    "    ---------\n",
    "    - df => Pandas DataFrame to be preprocessed\n",
    "    - date_column => Name of the column where the date is in\n",
    "    - [Optional] name_options (String) => options for the name_treatment function. Possible choice \"none\"(\"None\"), \"separate\", \"first\" (default) and \"last\"\n",
    "\n",
    "    Output:\n",
    "    ---------\n",
    "    - df => Preprocessed Pandas DataFrame\n",
    "    \"\"\"\n",
    "    if 'qty' in df.columns and 'amount' in df.columns:\n",
    "        # Create 'revenue' column as product of 'quantity' and 'amount'\n",
    "        df['revenue'] = df['qty'] * df['amount']\n",
    "\n",
    "    # only modify the name (last_name, first_name columns) if the parameter is not none\n",
    "    if name_options != \"none\" and name_options != \"None\":\n",
    "        df = name_treatment(df,name_options)\n",
    "    # use the function parse_dates to treat the date column of the dataset\n",
    "    df = parse_dates(df,date_column,date_format)\n",
    "    convert_string_columns(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8eead31",
   "metadata": {},
   "source": [
    "### Function for data exploration: displaying basic information on our dataset.\n",
    "We can see that there is no missing or NaN data since all columns have 10000 non-null rows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21203509",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore_data(df: pd.DataFrame) -> None:\n",
    "    \"\"\"\n",
    "    Prints key exploratory information: \n",
    "    - dataset shape (rows, columns)\n",
    "    - column data types\n",
    "    - missing values per column\n",
    "    - description of columns\n",
    "    - correlation matrix between numerical columns\n",
    "\n",
    "    Input:\n",
    "    ---------\n",
    "    - df => Pandas DataFrame to be explored\n",
    "\n",
    "    Output:\n",
    "    ---------\n",
    "    None (prints information to console)\n",
    "    \"\"\"\n",
    "    print(\"Shape (rows, columns):\", df.shape)\n",
    "\n",
    "    print(\"\\nColumn dtypes:\")\n",
    "    print(df.dtypes)\n",
    "\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    print(df.isna().sum())\n",
    "\n",
    "    print(\"\\nBasic description of numerical columns:\")\n",
    "    print(df.describe())\n",
    "\n",
    "    # Correlation matrix for numeric variables\n",
    "    if 'qty' in df.columns and 'amount' in df.columns and 'revenue' in df.columns:\n",
    "        print(\"\\nCorrelation matrix (numeric columns):\")\n",
    "        print(df[['qty', 'amount', 'revenue']].corr())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f04fbeae",
   "metadata": {},
   "source": [
    "### Testing data collection, preprocessing and exploration on the Invoices dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "db238c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>first_name</th>\n",
       "      <th>last_name</th>\n",
       "      <th>email</th>\n",
       "      <th>product_id</th>\n",
       "      <th>qty</th>\n",
       "      <th>amount</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>job</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carmen Nixon</td>\n",
       "      <td>Todd Anderson</td>\n",
       "      <td>marvinjackson@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>14.57</td>\n",
       "      <td>10/09/1982</td>\n",
       "      <td>283 Wendy Common</td>\n",
       "      <td>West Alexander</td>\n",
       "      <td>36239634</td>\n",
       "      <td>Logistics and distribution manager</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs. Heather Miller</td>\n",
       "      <td>Julia Moore</td>\n",
       "      <td>jeffrey84@example.net</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>65.48</td>\n",
       "      <td>03/10/2012</td>\n",
       "      <td>13567 Patricia Circles Apt. 751</td>\n",
       "      <td>Andreamouth</td>\n",
       "      <td>2820163</td>\n",
       "      <td>Osteopath</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crystal May</td>\n",
       "      <td>Philip Moody</td>\n",
       "      <td>ugoodman@example.com</td>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "      <td>24.66</td>\n",
       "      <td>23/03/1976</td>\n",
       "      <td>6389 Debbie Island Suite 470</td>\n",
       "      <td>Coxbury</td>\n",
       "      <td>27006726</td>\n",
       "      <td>Economist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Weber</td>\n",
       "      <td>Mark Scott</td>\n",
       "      <td>ssanchez@example.com</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "      <td>21.34</td>\n",
       "      <td>17/08/1986</td>\n",
       "      <td>6362 Ashley Plaza Apt. 994</td>\n",
       "      <td>Ninaland</td>\n",
       "      <td>83036521</td>\n",
       "      <td>Sports administrator</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristen Welch</td>\n",
       "      <td>David David</td>\n",
       "      <td>cynthia66@example.net</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>83.90</td>\n",
       "      <td>11/06/1996</td>\n",
       "      <td>463 Steven Cliffs Suite 757</td>\n",
       "      <td>Isaiahview</td>\n",
       "      <td>80142652</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Daniel Chapman</td>\n",
       "      <td>Ralph Price</td>\n",
       "      <td>davidrice@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>39.82</td>\n",
       "      <td>14/05/2004</td>\n",
       "      <td>8220 Stewart Isle Apt. 382</td>\n",
       "      <td>New Willieberg</td>\n",
       "      <td>53513212</td>\n",
       "      <td>Surveyor, insurance</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Jonathan Cabrera</td>\n",
       "      <td>John Baldwin</td>\n",
       "      <td>jennifer66@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>21.94</td>\n",
       "      <td>07/10/1994</td>\n",
       "      <td>48045 Harris Mountain Apt. 857</td>\n",
       "      <td>Jameston</td>\n",
       "      <td>61754737</td>\n",
       "      <td>Writer</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>David Thomas</td>\n",
       "      <td>Brandy Bishop</td>\n",
       "      <td>moraleskimberly@example.org</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>62.05</td>\n",
       "      <td>27/06/2010</td>\n",
       "      <td>872 Tonya Drive</td>\n",
       "      <td>West Eric</td>\n",
       "      <td>17037907</td>\n",
       "      <td>Surveyor, quantity</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Rose Bond</td>\n",
       "      <td>Daniel Lopez</td>\n",
       "      <td>vleon@example.net</td>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>11.35</td>\n",
       "      <td>16/01/2011</td>\n",
       "      <td>635 Saunders Creek Suite 967</td>\n",
       "      <td>Port Catherine</td>\n",
       "      <td>32764659</td>\n",
       "      <td>Architectural technologist</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Jeffrey Johnson</td>\n",
       "      <td>Yolanda Mcgrath</td>\n",
       "      <td>mchen@example.net</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>39.04</td>\n",
       "      <td>25/07/2021</td>\n",
       "      <td>783 Owens Way</td>\n",
       "      <td>Lake Ashleyborough</td>\n",
       "      <td>52015342</td>\n",
       "      <td>Designer, textile</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 11 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               first_name        last_name                        email  \\\n",
       "0            Carmen Nixon    Todd Anderson    marvinjackson@example.com   \n",
       "1     Mrs. Heather Miller      Julia Moore        jeffrey84@example.net   \n",
       "2             Crystal May     Philip Moody         ugoodman@example.com   \n",
       "3             Bobby Weber       Mark Scott         ssanchez@example.com   \n",
       "4           Kristen Welch      David David        cynthia66@example.net   \n",
       "...                   ...              ...                          ...   \n",
       "9995       Daniel Chapman      Ralph Price        davidrice@example.com   \n",
       "9996     Jonathan Cabrera     John Baldwin       jennifer66@example.com   \n",
       "9997         David Thomas    Brandy Bishop  moraleskimberly@example.org   \n",
       "9998            Rose Bond     Daniel Lopez            vleon@example.net   \n",
       "9999      Jeffrey Johnson  Yolanda Mcgrath            mchen@example.net   \n",
       "\n",
       "      product_id  qty  amount invoice_date                          address  \\\n",
       "0            133    9   14.57   10/09/1982                 283 Wendy Common   \n",
       "1            155    5   65.48   03/10/2012  13567 Patricia Circles Apt. 751   \n",
       "2            151    9   24.66   23/03/1976     6389 Debbie Island Suite 470   \n",
       "3            143    4   21.34   17/08/1986       6362 Ashley Plaza Apt. 994   \n",
       "4            168    2   83.90   11/06/1996      463 Steven Cliffs Suite 757   \n",
       "...          ...  ...     ...          ...                              ...   \n",
       "9995         133    1   39.82   14/05/2004       8220 Stewart Isle Apt. 382   \n",
       "9996         133    1   21.94   07/10/1994   48045 Harris Mountain Apt. 857   \n",
       "9997         173    2   62.05   27/06/2010                  872 Tonya Drive   \n",
       "9998         146    5   11.35   16/01/2011     635 Saunders Creek Suite 967   \n",
       "9999         193    2   39.04   25/07/2021                    783 Owens Way   \n",
       "\n",
       "                    city  stock_code                                 job  \n",
       "0         West Alexander    36239634  Logistics and distribution manager  \n",
       "1            Andreamouth     2820163                           Osteopath  \n",
       "2                Coxbury    27006726                           Economist  \n",
       "3               Ninaland    83036521                Sports administrator  \n",
       "4             Isaiahview    80142652             Chief Marketing Officer  \n",
       "...                  ...         ...                                 ...  \n",
       "9995      New Willieberg    53513212                 Surveyor, insurance  \n",
       "9996            Jameston    61754737                              Writer  \n",
       "9997           West Eric    17037907                  Surveyor, quantity  \n",
       "9998      Port Catherine    32764659          Architectural technologist  \n",
       "9999  Lake Ashleyborough    52015342                   Designer, textile  \n",
       "\n",
       "[10000 rows x 11 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('invoices.csv')\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cdf66a05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Shape (rows, columns): (10000, 15)\n",
      "\n",
      "Column dtypes:\n",
      "name                    object\n",
      "email                   object\n",
      "product_id               int64\n",
      "qty                      int64\n",
      "amount                 float64\n",
      "invoice_date    datetime64[ns]\n",
      "address                 object\n",
      "city                    object\n",
      "stock_code               int64\n",
      "job                     object\n",
      "revenue                float64\n",
      "year                     int32\n",
      "month                    int32\n",
      "day                      int32\n",
      "dayofweek                int32\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "name            0\n",
      "email           0\n",
      "product_id      0\n",
      "qty             0\n",
      "amount          0\n",
      "invoice_date    0\n",
      "address         0\n",
      "city            0\n",
      "stock_code      0\n",
      "job             0\n",
      "revenue         0\n",
      "year            0\n",
      "month           0\n",
      "day             0\n",
      "dayofweek       0\n",
      "dtype: int64\n",
      "\n",
      "Basic description of numerical columns:\n",
      "         product_id           qty        amount                invoice_date  \\\n",
      "count  10000.000000  10000.000000  10000.000000                       10000   \n",
      "mean     149.746700      5.005900     52.918236  1995-06-11 13:32:18.240000   \n",
      "min      100.000000      1.000000      5.010000         1970-01-05 00:00:00   \n",
      "25%      125.000000      3.000000     29.137500         1982-08-02 00:00:00   \n",
      "50%      150.000000      5.000000     53.485000         1994-12-26 00:00:00   \n",
      "75%      175.000000      7.000000     76.520000         2008-03-01 12:00:00   \n",
      "max      199.000000      9.000000     99.990000         2022-01-17 00:00:00   \n",
      "std       28.728186      2.576767     27.434579                         NaN   \n",
      "\n",
      "         stock_code       revenue          year         month           day  \\\n",
      "count  1.000000e+04  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean   4.950036e+07    265.687038   1994.941400      6.541900     15.869600   \n",
      "min    1.977000e+03      5.070000   1970.000000      1.000000      1.000000   \n",
      "25%    2.425234e+07     93.602500   1982.000000      4.000000      8.000000   \n",
      "50%    4.931714e+07    205.940000   1994.000000      7.000000     16.000000   \n",
      "75%    7.457446e+07    391.672500   2008.000000     10.000000     24.000000   \n",
      "max    9.999216e+07    898.920000   2022.000000     12.000000     31.000000   \n",
      "std    2.903081e+07    208.084624     14.880414      3.439975      8.867438   \n",
      "\n",
      "          dayofweek  \n",
      "count  10000.000000  \n",
      "mean       3.003200  \n",
      "min        0.000000  \n",
      "25%        1.000000  \n",
      "50%        3.000000  \n",
      "75%        5.000000  \n",
      "max        6.000000  \n",
      "std        2.009775  \n",
      "\n",
      "Correlation matrix (numeric columns):\n",
      "              qty    amount   revenue\n",
      "qty      1.000000  0.011086  0.660933\n",
      "amount   0.011086  1.000000  0.675678\n",
      "revenue  0.660933  0.675678  1.000000\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>product_id</th>\n",
       "      <th>qty</th>\n",
       "      <th>amount</th>\n",
       "      <th>invoice_date</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>stock_code</th>\n",
       "      <th>job</th>\n",
       "      <th>revenue</th>\n",
       "      <th>year</th>\n",
       "      <th>month</th>\n",
       "      <th>day</th>\n",
       "      <th>dayofweek</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Carmen Nixon</td>\n",
       "      <td>marvinjackson@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>9</td>\n",
       "      <td>14.57</td>\n",
       "      <td>1982-09-10</td>\n",
       "      <td>283 Wendy Common</td>\n",
       "      <td>West Alexander</td>\n",
       "      <td>36239634</td>\n",
       "      <td>Logistics and distribution manager</td>\n",
       "      <td>131.13</td>\n",
       "      <td>1982</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Mrs. Heather Miller</td>\n",
       "      <td>jeffrey84@example.net</td>\n",
       "      <td>155</td>\n",
       "      <td>5</td>\n",
       "      <td>65.48</td>\n",
       "      <td>2012-10-03</td>\n",
       "      <td>13567 Patricia Circles Apt. 751</td>\n",
       "      <td>Andreamouth</td>\n",
       "      <td>2820163</td>\n",
       "      <td>Osteopath</td>\n",
       "      <td>327.40</td>\n",
       "      <td>2012</td>\n",
       "      <td>10</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Crystal May</td>\n",
       "      <td>ugoodman@example.com</td>\n",
       "      <td>151</td>\n",
       "      <td>9</td>\n",
       "      <td>24.66</td>\n",
       "      <td>1976-03-23</td>\n",
       "      <td>6389 Debbie Island Suite 470</td>\n",
       "      <td>Coxbury</td>\n",
       "      <td>27006726</td>\n",
       "      <td>Economist</td>\n",
       "      <td>221.94</td>\n",
       "      <td>1976</td>\n",
       "      <td>3</td>\n",
       "      <td>23</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Bobby Weber</td>\n",
       "      <td>ssanchez@example.com</td>\n",
       "      <td>143</td>\n",
       "      <td>4</td>\n",
       "      <td>21.34</td>\n",
       "      <td>1986-08-17</td>\n",
       "      <td>6362 Ashley Plaza Apt. 994</td>\n",
       "      <td>Ninaland</td>\n",
       "      <td>83036521</td>\n",
       "      <td>Sports administrator</td>\n",
       "      <td>85.36</td>\n",
       "      <td>1986</td>\n",
       "      <td>8</td>\n",
       "      <td>17</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Kristen Welch</td>\n",
       "      <td>cynthia66@example.net</td>\n",
       "      <td>168</td>\n",
       "      <td>2</td>\n",
       "      <td>83.90</td>\n",
       "      <td>1996-06-11</td>\n",
       "      <td>463 Steven Cliffs Suite 757</td>\n",
       "      <td>Isaiahview</td>\n",
       "      <td>80142652</td>\n",
       "      <td>Chief Marketing Officer</td>\n",
       "      <td>167.80</td>\n",
       "      <td>1996</td>\n",
       "      <td>6</td>\n",
       "      <td>11</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Daniel Chapman</td>\n",
       "      <td>davidrice@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>39.82</td>\n",
       "      <td>2004-05-14</td>\n",
       "      <td>8220 Stewart Isle Apt. 382</td>\n",
       "      <td>New Willieberg</td>\n",
       "      <td>53513212</td>\n",
       "      <td>Surveyor, insurance</td>\n",
       "      <td>39.82</td>\n",
       "      <td>2004</td>\n",
       "      <td>5</td>\n",
       "      <td>14</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Jonathan Cabrera</td>\n",
       "      <td>jennifer66@example.com</td>\n",
       "      <td>133</td>\n",
       "      <td>1</td>\n",
       "      <td>21.94</td>\n",
       "      <td>1994-10-07</td>\n",
       "      <td>48045 Harris Mountain Apt. 857</td>\n",
       "      <td>Jameston</td>\n",
       "      <td>61754737</td>\n",
       "      <td>Writer</td>\n",
       "      <td>21.94</td>\n",
       "      <td>1994</td>\n",
       "      <td>10</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>David Thomas</td>\n",
       "      <td>moraleskimberly@example.org</td>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>62.05</td>\n",
       "      <td>2010-06-27</td>\n",
       "      <td>872 Tonya Drive</td>\n",
       "      <td>West Eric</td>\n",
       "      <td>17037907</td>\n",
       "      <td>Surveyor, quantity</td>\n",
       "      <td>124.10</td>\n",
       "      <td>2010</td>\n",
       "      <td>6</td>\n",
       "      <td>27</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Rose Bond</td>\n",
       "      <td>vleon@example.net</td>\n",
       "      <td>146</td>\n",
       "      <td>5</td>\n",
       "      <td>11.35</td>\n",
       "      <td>2011-01-16</td>\n",
       "      <td>635 Saunders Creek Suite 967</td>\n",
       "      <td>Port Catherine</td>\n",
       "      <td>32764659</td>\n",
       "      <td>Architectural technologist</td>\n",
       "      <td>56.75</td>\n",
       "      <td>2011</td>\n",
       "      <td>1</td>\n",
       "      <td>16</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Jeffrey Johnson</td>\n",
       "      <td>mchen@example.net</td>\n",
       "      <td>193</td>\n",
       "      <td>2</td>\n",
       "      <td>39.04</td>\n",
       "      <td>2021-07-25</td>\n",
       "      <td>783 Owens Way</td>\n",
       "      <td>Lake Ashleyborough</td>\n",
       "      <td>52015342</td>\n",
       "      <td>Designer, textile</td>\n",
       "      <td>78.08</td>\n",
       "      <td>2021</td>\n",
       "      <td>7</td>\n",
       "      <td>25</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     name                        email  product_id  qty  \\\n",
       "0            Carmen Nixon    marvinjackson@example.com         133    9   \n",
       "1     Mrs. Heather Miller        jeffrey84@example.net         155    5   \n",
       "2             Crystal May         ugoodman@example.com         151    9   \n",
       "3             Bobby Weber         ssanchez@example.com         143    4   \n",
       "4           Kristen Welch        cynthia66@example.net         168    2   \n",
       "...                   ...                          ...         ...  ...   \n",
       "9995       Daniel Chapman        davidrice@example.com         133    1   \n",
       "9996     Jonathan Cabrera       jennifer66@example.com         133    1   \n",
       "9997         David Thomas  moraleskimberly@example.org         173    2   \n",
       "9998            Rose Bond            vleon@example.net         146    5   \n",
       "9999      Jeffrey Johnson            mchen@example.net         193    2   \n",
       "\n",
       "      amount invoice_date                          address  \\\n",
       "0      14.57   1982-09-10                 283 Wendy Common   \n",
       "1      65.48   2012-10-03  13567 Patricia Circles Apt. 751   \n",
       "2      24.66   1976-03-23     6389 Debbie Island Suite 470   \n",
       "3      21.34   1986-08-17       6362 Ashley Plaza Apt. 994   \n",
       "4      83.90   1996-06-11      463 Steven Cliffs Suite 757   \n",
       "...      ...          ...                              ...   \n",
       "9995   39.82   2004-05-14       8220 Stewart Isle Apt. 382   \n",
       "9996   21.94   1994-10-07   48045 Harris Mountain Apt. 857   \n",
       "9997   62.05   2010-06-27                  872 Tonya Drive   \n",
       "9998   11.35   2011-01-16     635 Saunders Creek Suite 967   \n",
       "9999   39.04   2021-07-25                    783 Owens Way   \n",
       "\n",
       "                    city  stock_code                                 job  \\\n",
       "0         West Alexander    36239634  Logistics and distribution manager   \n",
       "1            Andreamouth     2820163                           Osteopath   \n",
       "2                Coxbury    27006726                           Economist   \n",
       "3               Ninaland    83036521                Sports administrator   \n",
       "4             Isaiahview    80142652             Chief Marketing Officer   \n",
       "...                  ...         ...                                 ...   \n",
       "9995      New Willieberg    53513212                 Surveyor, insurance   \n",
       "9996            Jameston    61754737                              Writer   \n",
       "9997           West Eric    17037907                  Surveyor, quantity   \n",
       "9998      Port Catherine    32764659          Architectural technologist   \n",
       "9999  Lake Ashleyborough    52015342                   Designer, textile   \n",
       "\n",
       "      revenue  year  month  day  dayofweek  \n",
       "0      131.13  1982      9   10          4  \n",
       "1      327.40  2012     10    3          2  \n",
       "2      221.94  1976      3   23          1  \n",
       "3       85.36  1986      8   17          6  \n",
       "4      167.80  1996      6   11          1  \n",
       "...       ...   ...    ...  ...        ...  \n",
       "9995    39.82  2004      5   14          4  \n",
       "9996    21.94  1994     10    7          4  \n",
       "9997   124.10  2010      6   27          6  \n",
       "9998    56.75  2011      1   16          6  \n",
       "9999    78.08  2021      7   25          6  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = load_data('invoices.csv')\n",
    "df = preprocess_data(df, date_column=\"invoice_date\", name_options=\"first\")\n",
    "explore_data(df)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6922243",
   "metadata": {},
   "source": [
    "## 2) Querying the dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aec97e1b",
   "metadata": {},
   "source": [
    "### Indicator 1: Grouping query (top cities by total revenue)\n",
    "- Revenue = Quantity * Amount. This is the total amount of a single transaction.\n",
    "- Identifies the most profitable geographic locations by aggregating total revenue by city.\n",
    "- Could potentially be used for business (targeted marketing, logistics, etc.)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d2d37bc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def indicator_top_group(df: pd.DataFrame, n: int = 10) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute top N group by total revenue.\n",
    "\n",
    "    This function groups invoices by 'city', sums the 'revenue' values and returns the top n cities ordered by total revenue descending.\n",
    "    \n",
    "    Input:\n",
    "    --------\n",
    "    - df: invoices DataFrame with 'city' and 'revenue' columns\n",
    "    - n: number of top cities to return\n",
    "    \n",
    "    Output:\n",
    "    --------\n",
    "    - DataFrame with columns ['city', 'total_revenue']\n",
    "    \"\"\"\n",
    "    # Check if revenue column exists, if not, create it from qty and amount\n",
    "    if 'revenue' not in df.columns:\n",
    "        if 'qty' in df.columns and 'amount' in df.columns:\n",
    "            df['revenue'] = df['qty'] * df['amount']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot calculate revenue: missing 'revenue' or 'qty'/'amount' columns\")\n",
    "    \n",
    "    # Group by city and sum the revenues\n",
    "    revenue_by_city = df.groupby('city').agg({\n",
    "        'revenue': 'sum',\n",
    "        'product_id': 'count'\n",
    "    }).reset_index()\n",
    "\n",
    "    revenue_by_city.columns = ['city', 'total_revenue', 'transaction_count']\n",
    "\n",
    "    # Sort by revenue descending\n",
    "    revenue_by_city = revenue_by_city.sort_values('total_revenue', ascending=False)\n",
    "\n",
    "    # Return the top n cities by total revenue\n",
    "    return revenue_by_city.head(n)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "95ccb6d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>city</th>\n",
       "      <th>total_revenue</th>\n",
       "      <th>transaction_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2864</th>\n",
       "      <td>Lake James</td>\n",
       "      <td>4417.17</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5395</th>\n",
       "      <td>Port Kimberly</td>\n",
       "      <td>3144.10</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4741</th>\n",
       "      <td>North Michael</td>\n",
       "      <td>2902.27</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6105</th>\n",
       "      <td>Smithmouth</td>\n",
       "      <td>2644.53</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6351</th>\n",
       "      <td>South Jennifer</td>\n",
       "      <td>2570.33</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5362</th>\n",
       "      <td>Port Joshua</td>\n",
       "      <td>2566.84</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>South James</td>\n",
       "      <td>2504.30</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2218</th>\n",
       "      <td>Jamesstad</td>\n",
       "      <td>2381.87</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3019</th>\n",
       "      <td>Lake Michael</td>\n",
       "      <td>2317.09</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6257</th>\n",
       "      <td>South David</td>\n",
       "      <td>2309.46</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                city  total_revenue  transaction_count\n",
       "2864      Lake James        4417.17                 12\n",
       "5395   Port Kimberly        3144.10                  6\n",
       "4741   North Michael        2902.27                  8\n",
       "6105      Smithmouth        2644.53                  8\n",
       "6351  South Jennifer        2570.33                  9\n",
       "5362     Port Joshua        2566.84                  7\n",
       "6334     South James        2504.30                 10\n",
       "2218       Jamesstad        2381.87                  5\n",
       "3019    Lake Michael        2317.09                  9\n",
       "6257     South David        2309.46                  9"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indicator_top_group(df, n=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e9330e17",
   "metadata": {},
   "source": [
    "### Indicator 2: Data transformation (revenue normalization by city)\n",
    "- Apply min‑max normalization or z‑score to city revenue to compare cities independently of absolute scale.\n",
    "- Min-Max normalization using the formula:\n",
    "    $$x_{\\text{norm}} = \\frac{x - \\min(x)}{\\max(x) - \\min(x)}$$\n",
    "    where x is the original revenue and min(x), max(x) are the minimum and maximum revenues across cities.\n",
    "\n",
    "- Z-Score normalization using the formula:\n",
    "    $$z = \\frac{x - \\mu}{\\sigma}$$\n",
    "    where $\\mu$ is the mean of $x$ and $\\sigma$ is the standard deviation of $x$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9abd75c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_city_revenue(city_rev: pd.DataFrame, method: str = 'min-max') -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Normalize total_revenue column using specified method.\n",
    "    \n",
    "    Input: \n",
    "    -------\n",
    "    - city_rev: DataFrame with 'city' and 'total_revenue'\n",
    "    - method: normalization method, either 'min-max', 'z-score' or 'both' (default 'min-max')\n",
    "    \n",
    "    Output: \n",
    "    ------\n",
    "    - same DataFrame with extra column 'revenue_norm'\n",
    "    \"\"\"\n",
    "    city_rev = city_rev.copy()\n",
    "\n",
    "    # Normalize the dataset with min-max normalization\n",
    "    if method in (\"minmax\", \"both\"):\n",
    "        min_val = city_rev[\"total_revenue\"].min()\n",
    "        max_val = city_rev[\"total_revenue\"].max()\n",
    "        city_rev[\"revenue_minmax\"] = (\n",
    "            (city_rev[\"total_revenue\"] - min_val) / (max_val - min_val)\n",
    "        )\n",
    "\n",
    "    # Normalize the dataset with z-score normalization\n",
    "    if method in (\"zscore\", \"both\"):\n",
    "        mean_val = city_rev[\"total_revenue\"].mean()\n",
    "        std_val = city_rev[\"total_revenue\"].std(ddof=0)\n",
    "        \n",
    "        # Put the revenue to 0 if std_val = 0 to not make a division by 0\n",
    "        if std_val != 0:\n",
    "            city_rev[\"revenue_zscore\"] = (\n",
    "                (city_rev[\"total_revenue\"] - mean_val) / std_val\n",
    "            )\n",
    "        else:\n",
    "            city_rev[\"revenue_zscore\"] = 0\n",
    "\n",
    "    return city_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5198cf5e",
   "metadata": {},
   "source": [
    "### Function to discretize city revenue, assigning to it revenue classes (low, medium, high). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "52c5c7ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def discretize_city_revenue(city_rev: pd.DataFrame, q: int = 3) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Discretize city revenue into q quantile-based categories.\n",
    "\n",
    "    Input:\n",
    "    --------\n",
    "    - city_rev: DataFrame with 'total_revenue'\n",
    "    - q: number of bins\n",
    "    \n",
    "    Output:\n",
    "    -------\n",
    "    - DataFrame with extra column 'revenue_segment'\n",
    "    \"\"\"\n",
    "    city_rev['revenue_segment'] = pd.qcut(\n",
    "        city_rev['total_revenue'],\n",
    "        q=q,\n",
    "        labels=[f\"Segment_{i+1}\" for i in range(q)]\n",
    "    )\n",
    "    return city_rev"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c17d27fd",
   "metadata": {},
   "source": [
    "### Indicator 2 (Version 2): Data Transformation - Customer Segmentation\n",
    "This indicator applies MinMax Normalization to standardize features and uses K-Means clustering to segment customers.\n",
    "\n",
    "This helps identify high-value customers for targeted marketing and retention strategies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "909de7e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customer_segmentation(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    - Applies MinMax normalization and K-Means clustering for segmentation.\n",
    "    - Segments customers into Low, Medium, and High value groups based on spending patterns.\n",
    "\n",
    "    Input:\n",
    "    --------\n",
    "    - df: invoices DataFrame\n",
    "    \n",
    "    Output:\n",
    "    --------\n",
    "    - DataFrame with customer revenue segmentation and detailed value ranges\n",
    "    \"\"\"\n",
    "    # Check if revenue column exists, if not, create it from qty and amount\n",
    "    if 'revenue' not in df.columns:\n",
    "        if 'qty' in df.columns and 'amount' in df.columns:\n",
    "            df['revenue'] = df['qty'] * df['amount']\n",
    "        else:\n",
    "            raise ValueError(\"Cannot calculate revenue: missing 'revenue' or 'qty'/'amount' columns\")\n",
    "\n",
    "    # Aggregate customer-level metrics\n",
    "    customer_profile = df.groupby(['name', 'email']).agg({\n",
    "        'revenue': ['sum', 'mean', 'count'],\n",
    "        'qty': 'sum'\n",
    "    }).reset_index()\n",
    "\n",
    "    customer_profile.columns = ['name', 'email',\n",
    "                                 'total_spent', 'avg_transaction',\n",
    "                                 'num_transactions', 'total_quantity']\n",
    "    \n",
    "    # Apply MinMax Normalization to features\n",
    "    features = ['total_spent', 'avg_transaction', 'num_transactions', 'total_quantity']\n",
    "    scaler = MinMaxScaler()\n",
    "    customer_profile[[f\"{f}_norm\" for f in features]] = scaler.fit_transform(customer_profile[features])\n",
    "\n",
    "    # Basic safety checks before clustering\n",
    "    if customer_profile.shape[0] < 3:\n",
    "        # Not enough samples for 3 clusters: we skip clustering and return profile\n",
    "        customer_profile['segment'] = 0\n",
    "        customer_profile['segment_label'] = 'Single/Small'\n",
    "        return customer_profile\n",
    "\n",
    "    # K-Means Clustering (3 clusters)\n",
    "    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)\n",
    "    customer_profile['segment'] = kmeans.fit_predict(customer_profile[['total_spent_norm', 'num_transactions_norm']])\n",
    "\n",
    "    # Label segments based on spending levels\n",
    "    segment_means = customer_profile.groupby('segment')['total_spent'].mean().sort_values()\n",
    "    segment_mapping = {\n",
    "        segment_means.index[0]: 'Low Value',\n",
    "        segment_means.index[1]: 'Medium Value',\n",
    "        segment_means.index[2]: 'High Value'\n",
    "    }\n",
    "    customer_profile['segment_label'] = customer_profile['segment'].map(segment_mapping)\n",
    "\n",
    "    print(\"Segment Distribution:\")\n",
    "    print(customer_profile['segment_label'].value_counts())\n",
    "\n",
    "    print(\"\\nSegment Revenue Ranges:\")\n",
    "    segment_stats = customer_profile.groupby('segment_label')['total_spent'].agg([\n",
    "        ('Count', 'count'),\n",
    "        ('Min Revenue', 'min'),\n",
    "        ('Max Revenue', 'max'),\n",
    "        ('Mean Revenue', 'mean'),\n",
    "        ('Median Revenue', 'median')\n",
    "    ]).round(2)\n",
    "    print(segment_stats)\n",
    "\n",
    "    print(\"\\nSegment Characteristics:\")\n",
    "    detailed_stats = customer_profile.groupby('segment_label').agg({\n",
    "        'total_spent': ['min', 'max', 'mean'],\n",
    "        'num_transactions': ['mean'],\n",
    "        'total_quantity': ['mean']\n",
    "    }).round(2)\n",
    "    print(detailed_stats)\n",
    "\n",
    "    # Add value range to each customer record\n",
    "    segment_ranges = customer_profile.groupby('segment_label')['total_spent'].agg(['min', 'max'])\n",
    "    customer_profile = customer_profile.merge(\n",
    "        segment_ranges, \n",
    "        left_on='segment_label', \n",
    "        right_index=True, \n",
    "        suffixes=('', '_segment')\n",
    "    )\n",
    "    customer_profile.rename(columns={'min': 'segment_min', 'max': 'segment_max'}, inplace=True)\n",
    "\n",
    "    # Create readable range label\n",
    "    customer_profile['value_range'] = customer_profile.apply(\n",
    "        lambda row: f\"${row['segment_min']:.2f} - ${row['segment_max']:.2f}\", \n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    return customer_profile"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6ded3926",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-4 (_readerthread):\n",
      "Traceback (most recent call last):\n",
      "  File \"c:\\Users\\leoma\\Documents\\anaconda3\\envs\\prophet_env\\Lib\\threading.py\", line 1045, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"c:\\Users\\leoma\\Documents\\anaconda3\\envs\\prophet_env\\Lib\\threading.py\", line 982, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"c:\\Users\\leoma\\Documents\\anaconda3\\envs\\prophet_env\\Lib\\subprocess.py\", line 1599, in _readerthread\n",
      "    buffer.append(fh.read())\n",
      "                  ^^^^^^^^^\n",
      "  File \"<frozen codecs>\", line 322, in decode\n",
      "UnicodeDecodeError: 'utf-8' codec can't decode byte 0x82 in position 126: invalid start byte\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Segment Distribution:\n",
      "segment_label\n",
      "Low Value       5305\n",
      "Medium Value    3085\n",
      "High Value      1610\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Segment Revenue Ranges:\n",
      "               Count  Min Revenue  Max Revenue  Mean Revenue  Median Revenue\n",
      "segment_label                                                               \n",
      "High Value      1610       491.50       898.92        640.53          623.20\n",
      "Low Value       5305         5.07       224.82        107.20           98.44\n",
      "Medium Value    3085       224.88       491.25        342.61          337.12\n",
      "\n",
      "Segment Characteristics:\n",
      "              total_spent                 num_transactions total_quantity\n",
      "                      min     max    mean             mean           mean\n",
      "segment_label                                                            \n",
      "High Value         491.50  898.92  640.53              1.0           7.83\n",
      "Low Value            5.07  224.82  107.20              1.0           3.65\n",
      "Medium Value       224.88  491.25  342.61              1.0           5.86\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "      <th>email</th>\n",
       "      <th>total_spent</th>\n",
       "      <th>avg_transaction</th>\n",
       "      <th>num_transactions</th>\n",
       "      <th>total_quantity</th>\n",
       "      <th>total_spent_norm</th>\n",
       "      <th>avg_transaction_norm</th>\n",
       "      <th>num_transactions_norm</th>\n",
       "      <th>total_quantity_norm</th>\n",
       "      <th>segment</th>\n",
       "      <th>segment_label</th>\n",
       "      <th>segment_min</th>\n",
       "      <th>segment_max</th>\n",
       "      <th>value_range</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Aaron Allen</td>\n",
       "      <td>ihogan@example.com</td>\n",
       "      <td>74.39</td>\n",
       "      <td>74.39</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.077552</td>\n",
       "      <td>0.077552</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Aaron Alvarez</td>\n",
       "      <td>anthony45@example.net</td>\n",
       "      <td>202.26</td>\n",
       "      <td>202.26</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.220607</td>\n",
       "      <td>0.220607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Aaron Bennett</td>\n",
       "      <td>miranda15@example.net</td>\n",
       "      <td>98.16</td>\n",
       "      <td>98.16</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0.104145</td>\n",
       "      <td>0.104145</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.250</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Aaron Brown</td>\n",
       "      <td>sergiozamora@example.org</td>\n",
       "      <td>19.14</td>\n",
       "      <td>19.14</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>0.015741</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Aaron Burns</td>\n",
       "      <td>josephanderson@example.org</td>\n",
       "      <td>187.68</td>\n",
       "      <td>187.68</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.204296</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9995</th>\n",
       "      <td>Zachary Thomas</td>\n",
       "      <td>annecunningham@example.net</td>\n",
       "      <td>379.08</td>\n",
       "      <td>379.08</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.418426</td>\n",
       "      <td>0.418426</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>224.88</td>\n",
       "      <td>491.25</td>\n",
       "      <td>$224.88 - $491.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9996</th>\n",
       "      <td>Zachary Thomas</td>\n",
       "      <td>jessicahenderson@example.net</td>\n",
       "      <td>592.34</td>\n",
       "      <td>592.34</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "      <td>0.657012</td>\n",
       "      <td>0.657012</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.750</td>\n",
       "      <td>1</td>\n",
       "      <td>High Value</td>\n",
       "      <td>491.50</td>\n",
       "      <td>898.92</td>\n",
       "      <td>$491.50 - $898.92</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9997</th>\n",
       "      <td>Zachary Weaver</td>\n",
       "      <td>catherine88@example.org</td>\n",
       "      <td>351.24</td>\n",
       "      <td>351.24</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>0.387280</td>\n",
       "      <td>0.387280</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.375</td>\n",
       "      <td>2</td>\n",
       "      <td>Medium Value</td>\n",
       "      <td>224.88</td>\n",
       "      <td>491.25</td>\n",
       "      <td>$224.88 - $491.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9998</th>\n",
       "      <td>Zoe Klein</td>\n",
       "      <td>joseph00@example.org</td>\n",
       "      <td>123.62</td>\n",
       "      <td>123.62</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>0.132629</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9999</th>\n",
       "      <td>Zoe Miller</td>\n",
       "      <td>patricia96@example.com</td>\n",
       "      <td>160.50</td>\n",
       "      <td>160.50</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0.173888</td>\n",
       "      <td>0.173888</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0</td>\n",
       "      <td>Low Value</td>\n",
       "      <td>5.07</td>\n",
       "      <td>224.82</td>\n",
       "      <td>$5.07 - $224.82</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10000 rows × 15 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                name                         email  total_spent  \\\n",
       "0        Aaron Allen            ihogan@example.com        74.39   \n",
       "1      Aaron Alvarez         anthony45@example.net       202.26   \n",
       "2      Aaron Bennett         miranda15@example.net        98.16   \n",
       "3        Aaron Brown      sergiozamora@example.org        19.14   \n",
       "4        Aaron Burns    josephanderson@example.org       187.68   \n",
       "...              ...                           ...          ...   \n",
       "9995  Zachary Thomas    annecunningham@example.net       379.08   \n",
       "9996  Zachary Thomas  jessicahenderson@example.net       592.34   \n",
       "9997  Zachary Weaver       catherine88@example.org       351.24   \n",
       "9998       Zoe Klein          joseph00@example.org       123.62   \n",
       "9999      Zoe Miller        patricia96@example.com       160.50   \n",
       "\n",
       "      avg_transaction  num_transactions  total_quantity  total_spent_norm  \\\n",
       "0               74.39                 1               1          0.077552   \n",
       "1              202.26                 1               3          0.220607   \n",
       "2               98.16                 1               3          0.104145   \n",
       "3               19.14                 1               2          0.015741   \n",
       "4              187.68                 1               2          0.204296   \n",
       "...               ...               ...             ...               ...   \n",
       "9995           379.08                 1               4          0.418426   \n",
       "9996           592.34                 1               7          0.657012   \n",
       "9997           351.24                 1               4          0.387280   \n",
       "9998           123.62                 1               2          0.132629   \n",
       "9999           160.50                 1               5          0.173888   \n",
       "\n",
       "      avg_transaction_norm  num_transactions_norm  total_quantity_norm  \\\n",
       "0                 0.077552                    0.0                0.000   \n",
       "1                 0.220607                    0.0                0.250   \n",
       "2                 0.104145                    0.0                0.250   \n",
       "3                 0.015741                    0.0                0.125   \n",
       "4                 0.204296                    0.0                0.125   \n",
       "...                    ...                    ...                  ...   \n",
       "9995              0.418426                    0.0                0.375   \n",
       "9996              0.657012                    0.0                0.750   \n",
       "9997              0.387280                    0.0                0.375   \n",
       "9998              0.132629                    0.0                0.125   \n",
       "9999              0.173888                    0.0                0.500   \n",
       "\n",
       "      segment segment_label  segment_min  segment_max        value_range  \n",
       "0           0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "1           0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "2           0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "3           0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "4           0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "...       ...           ...          ...          ...                ...  \n",
       "9995        2  Medium Value       224.88       491.25  $224.88 - $491.25  \n",
       "9996        1    High Value       491.50       898.92  $491.50 - $898.92  \n",
       "9997        2  Medium Value       224.88       491.25  $224.88 - $491.25  \n",
       "9998        0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "9999        0     Low Value         5.07       224.82    $5.07 - $224.82  \n",
       "\n",
       "[10000 rows x 15 columns]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "customer_segmentation(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74b03b98",
   "metadata": {},
   "source": [
    "### Indicator 3: Temporal Analysis - Revenue Forecasting\n",
    "Function for temporal prediction of the revenue."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5d9de3ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def temporal_prediction(df: pd.DataFrame, time: str=\"year\",periods: int = 10):\n",
    "    \"\"\"\n",
    "    Use Prophet model to make a temporal prediction of the revenue.\n",
    "\n",
    "    Inputs:\n",
    "    ---------\n",
    "    - df (DataFrame): Input dataset\n",
    "    - [Optionnal] time (str): options for the prediction between \"year\", \"month\" and \"day\".  \n",
    "        - \"year\" (default): use the year column of the dataset to make the prediction.  \n",
    "        - \"month\": use the month column of the dataset to make the prediction. \n",
    "        - \"day\": use the invoice_date column containing the full date to make the prediction\n",
    "    - [Optional] periods (int): The period to calculate the future date. Default 10.\n",
    "\n",
    "    Outputs: \n",
    "    --------\n",
    "    - new_df (DataFrame) - Contains 'time', 'original_revenue' and 'predicted_revenue'.\n",
    "    - model (Prophet) - Prophet model trained on the dataset and used for the prediction\n",
    "    - prediction (DataFrame) - Future prediction made by the model\n",
    "    \"\"\"\n",
    "    dataset = df.copy()\n",
    "    if time == \"year\":\n",
    "        # A mettre ailleur la transformation en datetime ?\n",
    "        dataset['year'] = pd.to_datetime(dataset['year'], format='%Y')\n",
    "\n",
    "        # Put the future date to year and group the revenue by year\n",
    "        freq = 'YE'\n",
    "        dataset = dataset.groupby('year')['revenue'].sum().reset_index()\n",
    "        # Rename the column to the name that the Prophet model will need\n",
    "        dataset.rename(columns={'year': 'ds','revenue': 'y'}, inplace=True)\n",
    "\n",
    "    elif time == \"month\":\n",
    "        # A mettre ailleur la transformation en datetime ?\n",
    "        dataset['month'] = dataset['year'].astype(str) + '-' + dataset['month'].astype(str).str.zfill(2)\n",
    "        dataset['month'] = pd.to_datetime(dataset['month'], format='%Y-%m')\n",
    "\n",
    "        # Put the future date to month and group the revenue by month\n",
    "        freq = 'ME'\n",
    "        dataset = dataset.groupby('month')['revenue'].sum().reset_index()\n",
    "        # Rename the column to the name that the Prophet model will need\n",
    "        dataset.rename(columns={'month': 'ds','revenue': 'y'}, inplace=True)\n",
    "    elif time == \"day\":\n",
    "\n",
    "        # Put the future date to day and group the revenue by day\n",
    "        freq = 'D'\n",
    "        dataset = dataset.groupby('invoice_date')['revenue'].sum().reset_index()\n",
    "        # Rename the column to the name that the Prophet model will need\n",
    "        dataset.rename(columns={'invoice_date': 'ds','revenue': 'y'}, inplace=True)\n",
    "    else:\n",
    "        print(\"Erreur: L'option 'time' doit être 'year', 'month' ou 'day.\")\n",
    "        return df,None,None\n",
    "\n",
    "    # Put cmdstanpy log ouput at ERROR to not have the output from Prophet model when it is used without trouble\n",
    "    logging.getLogger('cmdstanpy').setLevel(logging.ERROR)\n",
    "\n",
    "    # Create a Prophet model to make prediction\n",
    "    model = Prophet()\n",
    "    model.fit(dataset)\n",
    "\n",
    "    # get the date to predict and then use the predict function on these date to obtain the prediction\n",
    "    future_dates = model.make_future_dataframe(periods=periods, freq=freq)\n",
    "    prediction = model.predict(future_dates)\n",
    "\n",
    "    # Create a dataset with both original value and predicted value\n",
    "    # Then rename the new dataset columns with original_revenue and predicted_revenue\n",
    "    new_df = pd.merge(dataset[['ds', 'y']], prediction[['ds', 'yhat']], on='ds', how='outer')\n",
    "    new_df.rename(columns={'y': 'original_revenue','yhat': 'predicted_revenue', 'ds': 'time'}, inplace=True)\n",
    "    \n",
    "    return new_df, model,prediction\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57e42a22",
   "metadata": {},
   "source": [
    "### Function to create a visualization based on a temporal prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "480f723f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def display_temporal_prediction(df: pd.DataFrame, model,prediction,options: str = \"prophet\"):\n",
    "    \"\"\"\n",
    "    Create a visualization of the a dataset with temporal prediction \n",
    "    either with the dataset or with the prediction model.\n",
    "\n",
    "    Inputs:\n",
    "    ---------  \n",
    "    - df (DataFrame): Input dataset.\n",
    "    - model (Prophet): Prophet model trained on the dataset and used for the prediction.\n",
    "    - prediction (DataFrame): Future prediction made by the model.\n",
    "    - [Optional] options (str): options for the visualization between \"ploty\" and \"prophet\". \n",
    "        - \"prophet\" (default): use prophet default plot function to plot the prediction.   \n",
    "        - \"ploty\": use ploty to plot the prediction.  \n",
    "\n",
    "    Outputs: \n",
    "    --------\n",
    "    - fig (Figure) - A figure containing the temporal visualization.\n",
    "    \"\"\"\n",
    "\n",
    "    # Create a visualization using ploty express library\n",
    "    if options==\"ploty\":\n",
    "        if 'predicted_revenue' in df.columns and 'original_revenue' in df.columns:\n",
    "            fig = px.area()\n",
    "            fig.add_scatter(x=df.index, y=df[\"original_revenue\"], mode='lines', line=dict(color='blue'), name=\"original\")\n",
    "            fig.add_scatter(x=df.index ,y=df[\"predicted_revenue\"], mode='lines', line=dict(color='green'), name=\"prediction\")\n",
    "            fig.update_layout(title=\"Prediction\", xaxis_title=\"Date\", yaxis_title=\"Revenue\")\n",
    "        else:\n",
    "            print(\"Error, the prediction was not found in the dataset\")\n",
    "            fig = None\n",
    "\n",
    "    # use the plot_ploty from prohet to get a visualization\n",
    "    elif options == \"prophet\":\n",
    "        if model is not None:\n",
    "            fig = plot_plotly(model, prediction)\n",
    "        else:\n",
    "            print(\"Error, the prediction model was not found\")\n",
    "            fig = None\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2835a894",
   "metadata": {},
   "source": [
    "### Indicator 4: Spatial Analysis - Geographic Clustering\n",
    "This indicator applies K-Means clustering to group cities into activity levels based on revenue patterns (revenue = qty × amount)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6afefe6d",
   "metadata": {},
   "source": [
    "Function to analyze geographic distribution. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1797bfb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_geographic_distribution(df: pd.DataFrame) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Analyzes spatial distribution of transactions across cities.\n",
    "    Calculates revenue metrics and transaction patterns by location.\n",
    "\n",
    "    Input:\n",
    "    ---------\n",
    "    - df => Pandas DataFrame with city and revenue information\n",
    "\n",
    "    Output:\n",
    "    ---------\n",
    "    - city_stats => DataFrame with city-level statistics\n",
    "    \"\"\"\n",
    "    # Check if revenue column exists\n",
    "    if 'revenue' not in df.columns:\n",
    "        if 'qty' in df.columns and 'amount' in df.columns:\n",
    "            df['revenue'] = df['qty'] * df['amount']\n",
    "            print(\"Revenue column not found, creating it now...\")\n",
    "        else:\n",
    "            raise ValueError(\"Cannot calculate revenue: missing 'revenue' or 'qty'/'amount' columns\")\n",
    "\n",
    "    city_stats = df.groupby('city').agg({\n",
    "        'revenue': ['sum', 'mean', 'std'],\n",
    "        'qty': 'sum',\n",
    "        'product_id': 'count'\n",
    "    }).reset_index()\n",
    "\n",
    "    city_stats.columns = ['city', 'total_revenue', 'avg_revenue', 'std_revenue',\n",
    "                          'total_quantity', 'transaction_count']\n",
    "\n",
    "    city_stats['revenue_per_transaction'] = (\n",
    "        city_stats['total_revenue'] / city_stats['transaction_count'])\n",
    "\n",
    "    city_stats = city_stats.sort_values('total_revenue', ascending=False)\n",
    "\n",
    "    return city_stats"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df8db341",
   "metadata": {},
   "source": [
    "Function for spatial clustering, grouping cities by revenue patterns using KMeans clustering."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7479e700",
   "metadata": {},
   "outputs": [],
   "source": [
    "def spatial_clustering(city_stats: pd.DataFrame, n_clusters: int = 4) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Applies K-Means clustering to group cities by revenue patterns.\n",
    "    Uses normalized features: total revenue, transaction count, and\n",
    "    average order value. Identifies geographic market segments.\n",
    "\n",
    "    Input:\n",
    "    ---------\n",
    "    - city_stats => DataFrame with city-level statistics\n",
    "    - n_clusters => Integer, number of clusters (default: 4)\n",
    "\n",
    "    Output:\n",
    "    ---------\n",
    "    - city_stats => DataFrame with cluster labels added\n",
    "    \"\"\"\n",
    "    features = ['total_revenue', 'transaction_count', 'revenue_per_transaction']\n",
    "\n",
    "    # Normalize features\n",
    "    scaler = MinMaxScaler()\n",
    "    city_stats_norm = city_stats.copy()\n",
    "    city_stats_norm[features] = scaler.fit_transform(city_stats[features])\n",
    "\n",
    "    # Apply K-Means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    city_stats['cluster'] = kmeans.fit_predict(city_stats_norm[features])\n",
    "\n",
    "    # Label clusters by activity level\n",
    "    cluster_means = city_stats.groupby('cluster')['total_revenue'].mean().sort_values()\n",
    "    cluster_labels = {\n",
    "        cluster_means.index[0]: 'Low Activity',\n",
    "        cluster_means.index[1]: 'Medium-Low Activity',\n",
    "        cluster_means.index[2]: 'Medium-High Activity',\n",
    "        cluster_means.index[3]: 'High Activity'\n",
    "    }\n",
    "    city_stats['cluster_label'] = city_stats['cluster'].map(cluster_labels)\n",
    "    \n",
    "    print(\"Cluster Distribution:\")\n",
    "    print(city_stats['cluster_label'].value_counts())\n",
    "    print(\"\\nCluster Characteristics:\")\n",
    "    print(city_stats.groupby('cluster_label')[['total_revenue', 'transaction_count']].mean())\n",
    "\n",
    "    return city_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c75c1291",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fusion_dataset(df: pd.DataFrame, df_extra: pd.DataFrame)->pd.DataFrame:\n",
    "    '''\n",
    "    Create a new dataset taking information from both dataset.\n",
    "    This fonction was made for 2 dataset:\n",
    "    - https://www.kaggle.com/datasets/cankatsrc/invoices\n",
    "    - https://www.kaggle.com/datasets/ghassenkhaled/invoices-data\n",
    "\n",
    "    Input:\n",
    "    -------\n",
    "    - df: pd.DataFrame, first dataset\n",
    "    - df_extra: pd.DataFrame, second dataset\n",
    "\n",
    "    Ouput:\n",
    "    -------\n",
    "    - pd.DataFrame, new dataset\n",
    "    '''\n",
    "    df_base = df.copy()         # To make sure to not modify the base dataset\n",
    "    df_base['country'] = 'mars' # fictional country because randomly generated dataset\n",
    "    df_base = df_base[df_base['year']>2021] # because extra dataset contains recent dataset\n",
    "\n",
    "    df_extra = df_extra.drop(columns=['id_invoice','total','discount','tax','invoiceStatus','dueDate'])\n",
    "    df_base = df_base.drop(columns=['address','amount','email','product_id','qty','stock_code'])\n",
    "    df_extra.rename(columns={'issuedDate': 'invoice_date', 'service': 'job',\n",
    "                             'balance': 'revenue', 'client': 'name'}, inplace=True)\n",
    "    \n",
    "    \n",
    "    df_new = pd.concat([df_base, df_extra], ignore_index=True)\n",
    "    df_new = df_new.drop_duplicates()\n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "235e9c0b",
   "metadata": {},
   "source": [
    "## 3) Dash visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e9e43354",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_indicator(df: pd.DataFrame):\n",
    "    \"\"\"\n",
    "    Create visualization of some indicator on the dataset.\n",
    "\n",
    "    Input:\n",
    "    ---------\n",
    "    - df => Pandas DataFrame containing our cleaned dataset\n",
    "\n",
    "    Output:\n",
    "    ---------\n",
    "    - fig_top_cities_revenue => Visualization of the city who have the N(=10) best revenue\n",
    "    - fig_customer_segmentation => Visualization of the segmentation of the customers according to 3 class\n",
    "    - figure_pred_year => Visualization of the prediction of revenue according to yearly revenue\n",
    "    - figure_pred_month => Visualization of the prediction of revenue according to monthly revenue\n",
    "    - figure_pred_day => Visualization of the prediction of revenue according to daily revenue\n",
    "    - fig_spatial_clustering => Visualization of the city cluster by revenue and activity\n",
    "\n",
    "    \"\"\"\n",
    "                                        ### Indicator 1\n",
    "\n",
    "    # Creating the indicator\n",
    "    city_stats = indicator_top_group(df, n=10)\n",
    "\n",
    "    # Creating the vizualization\n",
    "    fig_top_cities_revenue = px.bar(\n",
    "        city_stats,\n",
    "        x='city',\n",
    "        y='total_revenue',\n",
    "        hover_data={'transaction_count': True, 'total_revenue': ':.2f'},\n",
    "        title='Top Cities by Revenue and Transactions',\n",
    "        labels={'city': 'City', 'total_revenue': 'Total Revenue ($)', 'transaction_count': 'Number of Transactions'},\n",
    "        color='transaction_count',\n",
    "        color_continuous_scale='Blues'\n",
    "    )\n",
    "    fig_top_cities_revenue.update_layout(\n",
    "        xaxis_tickangle=-45,\n",
    "        height=400,\n",
    "        showlegend=False,\n",
    "        hovermode='closest'\n",
    "    )\n",
    "\n",
    "                                        ### Indicator 2\n",
    "    \n",
    "    # Creating the indicator\n",
    "    customer_segments = customer_segmentation(df)\n",
    "\n",
    "    # Value ranges summary\n",
    "    segment_summary = customer_segments.groupby('segment_label').agg({\n",
    "        'total_spent': ['count', 'min', 'max', 'mean']\n",
    "    }).round(2)\n",
    "    segment_summary.columns = ['Count', 'Min', 'Max', 'Mean']\n",
    "    segment_summary = segment_summary.reset_index()\n",
    "\n",
    "     # Create custom labels with value ranges\n",
    "    segment_summary['label_with_range'] = segment_summary.apply(\n",
    "        lambda row: f\"{row['segment_label']}<br>${row['Min']:.2f} - ${row['Max']:.2f}<br>Avg: ${row['Mean']:.2f}\",\n",
    "        axis=1\n",
    "    )\n",
    "\n",
    "    # Creating the vizualization\n",
    "    fig_customer_segmentation = go.Figure(data=[go.Pie(\n",
    "        labels=segment_summary['label_with_range'],\n",
    "        values=segment_summary['Count'],\n",
    "        hole=0.4,\n",
    "        marker=dict(\n",
    "            colors=['#e74c3c', '#f39c12', '#27ae60'],\n",
    "            line=dict(color='white', width=2)\n",
    "        ),\n",
    "        textinfo='percent+value',\n",
    "        textposition='outside',\n",
    "        hovertemplate='<b>%{label}</b><br>Customers: %{value}<br>Percentage: %{percent}<extra></extra>'\n",
    "    )])\n",
    "    \n",
    "    fig_customer_segmentation.update_layout(\n",
    "        title={\n",
    "            'text': 'Customer Segmentation by Value<br><sub>With Revenue Ranges</sub>',\n",
    "            'x': 0.5,\n",
    "            'xanchor': 'center'\n",
    "        },\n",
    "        height=400,\n",
    "        showlegend=True,\n",
    "        legend=dict(\n",
    "            orientation=\"v\",\n",
    "            yanchor=\"middle\",\n",
    "            y=0.5,\n",
    "            xanchor=\"left\",\n",
    "            x=1.05,\n",
    "            font=dict(size=10)\n",
    "        ),\n",
    "        annotations=[dict(\n",
    "            text='Customer<br>Segments',\n",
    "            x=0.5, y=0.5,\n",
    "            font_size=14,\n",
    "            showarrow=False,\n",
    "            font=dict(color='#2c3e50', weight='bold')\n",
    "        )]\n",
    "    )\n",
    "\n",
    "                                        ### Indicator 3\n",
    "\n",
    "    ## To change the data used to make the prediction change time_pred,\n",
    "    ## Put the oldest date that you want to be taken in year.\n",
    "    ## In case you change time_pred and use the create_dashboard function,\n",
    "    ## change the year in year_to_index and the label in the Dropdown\n",
    "    time_pred = [1900, 2020, 2019, 2017, 2015, 2010, 2000, 1990, 1980]\n",
    "\n",
    "    ## To change how far the model should predict, change the prediction_lenght variable,\n",
    "    ## It must be a positive int number\n",
    "    prediction_lenght_year = 10\n",
    "    prediction_lenght_month = 24\n",
    "    prediction_lenght_day = 120\n",
    "\n",
    "    figure_pred_year = []\n",
    "    figure_pred_month = []\n",
    "    figure_pred_day = []\n",
    "\n",
    "    # Make the prediction using yearly, monthly and Daily data for every date in time_pred\n",
    "    for i in time_pred:\n",
    "        dataset = df.copy()\n",
    "        dataset = dataset[dataset[\"year\"]>i]\n",
    "\n",
    "        data_y, model_y,predictions_y = temporal_prediction(\n",
    "            dataset,time=\"year\", periods=prediction_lenght_year\n",
    "        )\n",
    "        figure_pred_year.append(\n",
    "            display_temporal_prediction(data_y,model_y,predictions_y)\n",
    "        )\n",
    "        data_m,model_m,predictions_m = temporal_prediction(\n",
    "            dataset,time=\"month\",periods=prediction_lenght_month\n",
    "        )\n",
    "        figure_pred_month.append(\n",
    "            display_temporal_prediction(data_m,model_m,predictions_m)\n",
    "        )\n",
    "        data_m,model_m,predictions_m = temporal_prediction(\n",
    "            dataset,time=\"day\",periods=prediction_lenght_day\n",
    "        )\n",
    "        figure_pred_day.append(\n",
    "            display_temporal_prediction(data_m,model_m,predictions_m)\n",
    "        )\n",
    "\n",
    "                                        ### Indicator 4\n",
    "\n",
    "    # Creating the indicator\n",
    "    city_clusters = spatial_clustering(analyze_geographic_distribution(df))\n",
    "    \n",
    "    # Creating the vizualization\n",
    "    fig_spatial_clustering = px.scatter(\n",
    "        city_clusters.head(3000),\n",
    "        x='transaction_count',\n",
    "        y='total_revenue',\n",
    "        color='cluster_label',\n",
    "        size='revenue_per_transaction',\n",
    "        hover_data=['city'],\n",
    "        labels={\n",
    "            'transaction_count': 'Number of Transactions',\n",
    "            'total_revenue': 'Total Revenue ($)',\n",
    "            'cluster_label': 'Activity Level'\n",
    "        },\n",
    "        color_discrete_map={\n",
    "            'Low Activity': 'red',\n",
    "            'Medium-Low Activity': 'orange',\n",
    "            'Medium-High Activity': 'blue',\n",
    "            'High Activity': 'green'\n",
    "        }\n",
    "    )\n",
    "    fig_spatial_clustering.update_layout(\n",
    "        title=dict(\n",
    "            text='City Clustering by Revenue and Activity',\n",
    "            x=0.5,\n",
    "            xanchor='center',\n",
    "            font=dict(size=16)\n",
    "        ),\n",
    "        margin=dict(l=60, r=40, t=80, b=60),\n",
    "        height=500\n",
    "    )\n",
    "\n",
    "    return (fig_top_cities_revenue, fig_customer_segmentation, figure_pred_year,\n",
    "            figure_pred_month, figure_pred_day, fig_spatial_clustering)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "69840c67",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_dashboard(df: pd.DataFrame, df_augmented: pd.DataFrame | None = None) -> Dash:\n",
    "    \"\"\"Create a Dash dashboard to visualize key business indicators from invoice data.\"\"\"\n",
    "    \n",
    "    # Generate visualizations with the create_indicator function\n",
    "    (fig_top_cities_revenue, fig_customer_segmentation, figure_pred_year,\n",
    "     figure_pred_month, figure_pred_day, fig_spatial_clustering) = create_indicator(df)\n",
    "\n",
    "    # Fix Prophet chart layouts\n",
    "    for fig_list in [figure_pred_year, figure_pred_month, figure_pred_day]:\n",
    "        for fig in fig_list:\n",
    "            fig.update_xaxes(title_text=\"Date\")\n",
    "            fig.update_yaxes(title_text=\"Revenue ($)\")\n",
    "            fig.update_layout(margin=dict(l=50, r=50, t=50, b=50))\n",
    "\n",
    "    # Dropdown mapping\n",
    "    year_to_index = {\n",
    "        'YA': 0, 'MA': 0, 'DA': 0,\n",
    "        'Y2020': 1, 'M2020': 1, 'D2020': 1,\n",
    "        'Y2019': 2, 'M2019': 2, 'D2019': 2,\n",
    "        'Y2017': 3, 'M2017': 3, 'D2017': 3,\n",
    "        'Y2015': 4, 'M2015': 4, 'D2015': 4,\n",
    "        'Y2010': 5, 'M2010': 5, 'D2010': 5,\n",
    "        'Y2000': 6, 'M2000': 6, 'D2000': 6,\n",
    "        'Y1990': 7, 'M1990': 7, 'D1990': 7,\n",
    "        'Y1980': 8, 'M1980': 8, 'D1980': 8,\n",
    "    }\n",
    "\n",
    "    # Initialize app\n",
    "    app = Dash(__name__, external_stylesheets=[\n",
    "        'https://fonts.googleapis.com/css2?family=Inter:wght@400;600;700&display=swap'\n",
    "    ])\n",
    "\n",
    "    # Colors\n",
    "    C = {\n",
    "        'primary': '#2c3e50', 'accent': '#3498db', 'success': '#27ae60',\n",
    "        'warning': '#f39c12', 'info': '#8e44ad', 'light': '#ecf0f1',\n",
    "        'white': '#fff', 'text': '#2c3e50', 'text_light': '#7f8c8d',\n",
    "        'border': '#bdc3c7', 'bg': '#fafafa'\n",
    "    }\n",
    "\n",
    "    # Card style\n",
    "    card = {\n",
    "        'backgroundColor': C['white'], 'borderRadius': '12px',\n",
    "        'boxShadow': '0 4px 12px rgba(0,0,0,0.1)', 'border': f'1px solid {C[\"border\"]}'\n",
    "    }\n",
    "\n",
    "    app.layout = html.Div([\n",
    "        # Header\n",
    "        html.Div([\n",
    "            html.H1('Invoices Data Analysis Dashboard', \n",
    "                   style={'margin': '0 0 10px', 'color': C['primary'], 'fontSize': '2.5rem', 'fontWeight': '700'}),\n",
    "            html.H3('Programming for Data Science - Final Project',\n",
    "                   style={'margin': '0 0 15px', 'color': C['primary'], 'fontSize': '1.3rem', 'fontWeight': '500'}),\n",
    "            html.Div([\n",
    "                html.Span('Team: ', style={'fontWeight': '600'}),\n",
    "                html.Span('Alvaro SERERO, Leo WINTER, Yoann SUBLET, Kellian VERVAELE KLEIN')\n",
    "            ], style={'fontSize': '0.95rem', 'color': C['text_light'], 'marginBottom': '5px'}),\n",
    "            html.Div([\n",
    "                html.Span('Dataset: ', style={'fontWeight': '600'}),\n",
    "                html.Span('Invoices (Kaggle) - 10,000 transactions')\n",
    "            ], style={'fontSize': '0.95rem', 'color': C['text_light']}),\n",
    "        ], style={'textAlign': 'center', 'padding': '40px 20px', 'backgroundColor': C['light'], \n",
    "                  'borderBottom': f'3px solid {C[\"accent\"]}', 'marginBottom': '40px'}),\n",
    "\n",
    "        html.Div([\n",
    "            # Row 1: Indicators 1 & 2\n",
    "            html.Div([\n",
    "                # Indicator 1\n",
    "                html.Div([\n",
    "                    html.H2('Indicator 1: Top Cities by Revenue',\n",
    "                           style={'color': C['accent'], 'fontSize': '1.5rem', 'fontWeight': '600', \n",
    "                                  'margin': '0 0 10px', 'padding': '20px 20px 0'}),\n",
    "                    html.P('Grouping Query - Revenue = Quantity × Price',\n",
    "                          style={'color': C['text_light'], 'fontSize': '0.9rem', 'margin': '0', 'padding': '0 20px 10px'}),\n",
    "                    dcc.Graph(figure=fig_top_cities_revenue, style={'height': '400px'}, config={'displayModeBar': False})\n",
    "                ], style={**card, 'overflow': 'hidden'}),\n",
    "\n",
    "                # Indicator 2\n",
    "                html.Div([\n",
    "                    html.H2('Indicator 2: Customer Segmentation',\n",
    "                           style={'color': C['success'], 'fontSize': '1.5rem', 'fontWeight': '600',\n",
    "                                  'margin': '0 0 10px', 'padding': '20px 20px 0'}),\n",
    "                    html.P('MinMax Normalization + K-Means (k=3) with value ranges',\n",
    "                          style={'color': C['text_light'], 'fontSize': '0.9rem', 'margin': '0', 'padding': '0 20px 10px'}),\n",
    "                    dcc.Graph(figure=fig_customer_segmentation, style={'height': '400px'}, config={'displayModeBar': False})\n",
    "                ], style={**card, 'overflow': 'hidden'})\n",
    "            ], style={'display': 'grid', 'gridTemplateColumns': 'repeat(auto-fit, minmax(500px, 1fr))', \n",
    "                     'gap': '30px', 'marginBottom': '30px'}),\n",
    "\n",
    "            # Row 2: Indicator 3\n",
    "            html.Div([\n",
    "                html.H2('Indicator 3: Revenue Forecasting',\n",
    "                       style={'color': C['info'], 'fontSize': '1.5rem', 'fontWeight': '600', 'marginBottom': '10px'}),\n",
    "                html.P('Prophet Model - Multiple time scales',\n",
    "                      style={'color': C['text_light'], 'fontSize': '0.9rem', 'marginBottom': '15px'}),\n",
    "                html.Div([\n",
    "                    html.Label('Select Time Period:', style={'fontWeight': '600', 'marginRight': '15px'}),\n",
    "                    dcc.Dropdown(\n",
    "                        id='dropdown',\n",
    "                        options=[\n",
    "                            {'label': 'All Years', 'value': 'YA'},\n",
    "                            {'label': '2020', 'value': 'Y2020'}, {'label': '2019', 'value': 'Y2019'},\n",
    "                            {'label': '2017', 'value': 'Y2017'}, {'label': '2015', 'value': 'Y2015'},\n",
    "                            {'label': '2010', 'value': 'Y2010'}, {'label': '2000', 'value': 'Y2000'},\n",
    "                            {'label': '1990', 'value': 'Y1990'}, {'label': '1980', 'value': 'Y1980'},\n",
    "                            {'label': 'All Months', 'value': 'MA'},\n",
    "                            {'label': '2020', 'value': 'M2020'}, {'label': '2019', 'value': 'M2019'},\n",
    "                            {'label': '2017', 'value': 'M2017'}, {'label': '2015', 'value': 'M2015'},\n",
    "                            {'label': '2010', 'value': 'M2010'}, {'label': '2000', 'value': 'M2000'},\n",
    "                            {'label': '1990', 'value': 'M1990'}, {'label': '1980', 'value': 'M1980'},\n",
    "                            {'label': 'All Days', 'value': 'DA'},\n",
    "                            {'label': '2020', 'value': 'D2020'}, {'label': '2019', 'value': 'D2019'},\n",
    "                            {'label': '2017', 'value': 'D2017'}, {'label': '2015', 'value': 'D2015'},\n",
    "                            {'label': '2010', 'value': 'D2010'},\n",
    "                        ],\n",
    "                        value='YA', clearable=False, style={'width': '250px'}\n",
    "                    )\n",
    "                ], style={'display': 'flex', 'alignItems': 'center', 'marginBottom': '20px'}),\n",
    "                dcc.Graph(id='graph', style={'height': '450px'})\n",
    "            ], style={**card, 'padding': '20px', 'marginBottom': '30px'}),\n",
    "\n",
    "            # Row 3: Indicator 4\n",
    "            html.Div([\n",
    "                html.H2('Indicator 4: Geographic Clustering',\n",
    "                       style={'color': C['warning'], 'fontSize': '1.5rem', 'fontWeight': '600', 'marginBottom': '10px'}),\n",
    "                html.P('K-Means Spatial Clustering - 4 activity levels',\n",
    "                      style={'color': C['text_light'], 'fontSize': '0.9rem', 'marginBottom': '15px'}),\n",
    "                dcc.Graph(figure=fig_spatial_clustering, style={'height': '500px'}, config={'displayModeBar': False})\n",
    "            ], style={**card, 'padding': '20px 20px 10px', 'marginBottom': '30px'})\n",
    "\n",
    "        ], style={'maxWidth': '1400px', 'margin': '0 auto', 'padding': '0 20px 40px'}),\n",
    "\n",
    "        # Footer\n",
    "        html.Div([\n",
    "            html.P('© 2025 Data Science Team | Built with Python, Dash, Plotly & Prophet',\n",
    "                  style={'textAlign': 'center', 'color': C['text_light'], 'fontSize': '0.85rem', 'margin': '0'})\n",
    "        ], style={'padding': '20px', 'backgroundColor': C['light'], 'borderTop': f'1px solid {C[\"border\"]}'})\n",
    "\n",
    "    ], style={'fontFamily': \"'Inter', sans-serif\", 'backgroundColor': C['bg'], 'minHeight': '100vh', 'margin': '0'})\n",
    "\n",
    "    # callback to get the information from the indicator 3 dropdown\n",
    "    \"\"\" \n",
    "                        Update_temporal_graph function\n",
    "    Function that work with the callback by taking \n",
    "    the dropdown value and returning the graph for indicator 3\n",
    "    input : the \"value\" variable of the dropdown id='dropdown'\n",
    "    output : the visualization containing revenue prediction made by the prophet model\n",
    "    \"\"\"\n",
    "    @callback(\n",
    "    Output('graph', 'figure'),\n",
    "    Input('dropdown', 'value'))\n",
    "    def update_temporal_graph(selected_value):\n",
    "        index = year_to_index[selected_value]\n",
    "        if selected_value.startswith(\"Y\"):\n",
    "            fig_dash = figure_pred_year[index]\n",
    "        elif selected_value.startswith(\"M\"):\n",
    "            fig_dash = figure_pred_month[index]\n",
    "        elif selected_value.startswith(\"D\"):\n",
    "            fig_dash = figure_pred_day[index]\n",
    "        \n",
    "        # Fix the chart layout\n",
    "        fig_dash.update_xaxes(title_text=\"\")\n",
    "        fig_dash.update_layout(\n",
    "            margin=dict(l=60, r=40, t=60, b=40),\n",
    "            xaxis_title=\"\",\n",
    "            height=450\n",
    "        )\n",
    "        \n",
    "        return fig_dash\n",
    "    return app"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "113feb76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loaded successfully.\n",
      "Shape (rows, columns): (10000, 15)\n",
      "\n",
      "Column dtypes:\n",
      "name                    object\n",
      "email                   object\n",
      "product_id               int64\n",
      "qty                      int64\n",
      "amount                 float64\n",
      "invoice_date    datetime64[ns]\n",
      "address                 object\n",
      "city                    object\n",
      "stock_code               int64\n",
      "job                     object\n",
      "revenue                float64\n",
      "year                     int32\n",
      "month                    int32\n",
      "day                      int32\n",
      "dayofweek                int32\n",
      "dtype: object\n",
      "\n",
      "Missing values per column:\n",
      "name            0\n",
      "email           0\n",
      "product_id      0\n",
      "qty             0\n",
      "amount          0\n",
      "invoice_date    0\n",
      "address         0\n",
      "city            0\n",
      "stock_code      0\n",
      "job             0\n",
      "revenue         0\n",
      "year            0\n",
      "month           0\n",
      "day             0\n",
      "dayofweek       0\n",
      "dtype: int64\n",
      "\n",
      "Basic description of numerical columns:\n",
      "         product_id           qty        amount                invoice_date  \\\n",
      "count  10000.000000  10000.000000  10000.000000                       10000   \n",
      "mean     149.746700      5.005900     52.918236  1995-06-11 13:32:18.240000   \n",
      "min      100.000000      1.000000      5.010000         1970-01-05 00:00:00   \n",
      "25%      125.000000      3.000000     29.137500         1982-08-02 00:00:00   \n",
      "50%      150.000000      5.000000     53.485000         1994-12-26 00:00:00   \n",
      "75%      175.000000      7.000000     76.520000         2008-03-01 12:00:00   \n",
      "max      199.000000      9.000000     99.990000         2022-01-17 00:00:00   \n",
      "std       28.728186      2.576767     27.434579                         NaN   \n",
      "\n",
      "         stock_code       revenue          year         month           day  \\\n",
      "count  1.000000e+04  10000.000000  10000.000000  10000.000000  10000.000000   \n",
      "mean   4.950036e+07    265.687038   1994.941400      6.541900     15.869600   \n",
      "min    1.977000e+03      5.070000   1970.000000      1.000000      1.000000   \n",
      "25%    2.425234e+07     93.602500   1982.000000      4.000000      8.000000   \n",
      "50%    4.931714e+07    205.940000   1994.000000      7.000000     16.000000   \n",
      "75%    7.457446e+07    391.672500   2008.000000     10.000000     24.000000   \n",
      "max    9.999216e+07    898.920000   2022.000000     12.000000     31.000000   \n",
      "std    2.903081e+07    208.084624     14.880414      3.439975      8.867438   \n",
      "\n",
      "          dayofweek  \n",
      "count  10000.000000  \n",
      "mean       3.003200  \n",
      "min        0.000000  \n",
      "25%        1.000000  \n",
      "50%        3.000000  \n",
      "75%        5.000000  \n",
      "max        6.000000  \n",
      "std        2.009775  \n",
      "\n",
      "Correlation matrix (numeric columns):\n",
      "              qty    amount   revenue\n",
      "qty      1.000000  0.011086  0.660933\n",
      "amount   0.011086  1.000000  0.675678\n",
      "revenue  0.660933  0.675678  1.000000\n",
      "Segment Distribution:\n",
      "segment_label\n",
      "Low Value       5305\n",
      "Medium Value    3085\n",
      "High Value      1610\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Segment Revenue Ranges:\n",
      "               Count  Min Revenue  Max Revenue  Mean Revenue  Median Revenue\n",
      "segment_label                                                               \n",
      "High Value      1610       491.50       898.92        640.53          623.20\n",
      "Low Value       5305         5.07       224.82        107.20           98.44\n",
      "Medium Value    3085       224.88       491.25        342.61          337.12\n",
      "\n",
      "Segment Characteristics:\n",
      "              total_spent                 num_transactions total_quantity\n",
      "                      min     max    mean             mean           mean\n",
      "segment_label                                                            \n",
      "High Value         491.50  898.92  640.53              1.0           7.83\n",
      "Low Value            5.07  224.82  107.20              1.0           3.65\n",
      "Medium Value       224.88  491.25  342.61              1.0           5.86\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "14:55:59 - cmdstanpy - INFO - Chain [1] start processing\n",
      "14:55:59 - cmdstanpy - INFO - Chain [1] done processing\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cluster Distribution:\n",
      "cluster_label\n",
      "Low Activity            3809\n",
      "Medium-Low Activity     2377\n",
      "Medium-High Activity    1182\n",
      "High Activity            405\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Cluster Characteristics:\n",
      "                      total_revenue  transaction_count\n",
      "cluster_label                                         \n",
      "High Activity           1086.379383           3.832099\n",
      "Low Activity             126.251166           1.134418\n",
      "Medium-High Activity     669.299958           1.079526\n",
      "Medium-Low Activity      397.510934           1.199411\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:8050/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x1b7f5679010>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def main():\n",
    "    file_path = \"invoices.csv\"\n",
    "    # https://www.kaggle.com/datasets/ghassenkhaled/invoices-data\n",
    "    file_path_extra = \"invoices_extra.csv\" \n",
    "    df = load_data(file_path)\n",
    "    df = preprocess_data(df,date_column=\"invoice_date\")\n",
    "    explore_data(df)\n",
    "\n",
    "    app = create_dashboard(df)\n",
    "    app.run()\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ec285a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "prophet_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
